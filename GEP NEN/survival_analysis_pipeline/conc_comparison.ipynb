{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from encoding import *\n",
    "from Survival_functions import *\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy.stats as stats\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path with the actual path to your file\n",
    "file_path = '../../../Both/new_study.xlsx'\n",
    "imputed_df = pd.read_excel(file_path, index_col='PATNO')\n",
    "imputed_df = imputed_df.rename(columns={'OS (days)': 'time'})\n",
    "imputed_df = imputed_df.rename(columns={'Status': 'status'})\n",
    "\n",
    "imputed_df['status'] = imputed_df['status'].map({'Dead': True, 'Alive': False})\n",
    "\n",
    "imputed_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "mcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=173637)\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import (concordance_index_censored, \n",
    "                            integrated_brier_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare\n",
    "- Dataset using KNN-imputation vs dataset without imputation method (remove samples, and columns)\n",
    "- This comparison is done for three models; Coxnet, CoxPH and RSF\n",
    "- All models find their best model within a range of hyperparameters that they use for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COXNET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COXNET (Unimputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Unimputed dataset, there are several methods for removing samples and columns. The `preprocess_data` function takes `NaN_threshold` as an argument to determine how many columns it removes before eliminating the samples. This threshold is a percentage, where any columns with a higher percentage of NaN values than the threshold are removed. Then, all samples containing NaN values are removed. The `NaN_threshold` serves as a hyperparameter to determine the optimal value alongside the other two hyperparameters, l1 ratio and alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for CoxPH model in sksurv\n",
    "alphas = [0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 3, 5, 10, 20, 50, 70, 100, 200, 500, 700, 1000]\n",
    "l1_ratios = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "preds_coxnet_mean_by_dataset = {}\n",
    "conc_coxnet_by_dataset = {}\n",
    "\n",
    "NaN_thresholds = [3, 4, 5]\n",
    "\n",
    "for NaN_threshold in NaN_thresholds:\n",
    "    print(NaN_threshold)\n",
    "    file_path = '../../../Both/new_study.xlsx'\n",
    "    df = pd.read_excel(file_path, index_col='PATNO')\n",
    "    df = df.rename(columns={'OS (days)': 'time'})\n",
    "    df = df.rename(columns={'Status': 'status'})\n",
    "    df['status'] = df['status'].map({'Dead': True, 'Alive': False})\n",
    "\n",
    "    df = preprocess_data(df, NaN_threshold)\n",
    "\n",
    "    X, y, tuple_y, target_columns = x_y_baseline(df)\n",
    "\n",
    "    unimp_results_coxnet = {}\n",
    "    unimp_conc_coxnet = {}\n",
    "\n",
    "    for l1_ratio in l1_ratios:\n",
    "        for alpha in alphas:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                \n",
    "                coxnet = CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alphas=[alpha], fit_baseline_model=True)\n",
    "                conc_train = []\n",
    "                conc_test = []\n",
    "                brier = []\n",
    "                permut = []\n",
    "                coef = []\n",
    "                feature_importance = []\n",
    "                \n",
    "                print(f'alpha: {alpha}, l1_ratio: {l1_ratio}')\n",
    "            \n",
    "                for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                    \n",
    "                    y_train, y_test = y[train], y[test]\n",
    "                    \n",
    "                    X_train, X_test = Preprocessing_without_imputing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                    # fix the times            \n",
    "                    times_train_min = y_train['time'].min()\n",
    "                    times_train_max = y_train['time'].max()\n",
    "                    times_train = np.arange(0, times_train_max)\n",
    "                    times_test_min = y_test['time'].min()\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                    if times_test_max > times_train_max:\n",
    "                        y_test_red_index = y_test['time'] <= times_train_max\n",
    "                        y_test = y_test[y_test_red_index]\n",
    "                        X_test = X_test[y_test_red_index]\n",
    "                        times_test_max = y_test['time'].max()\n",
    "                    times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                    \n",
    "                    coxnet.fit(X_train, y_train)\n",
    "                    \n",
    "                    # Compute the C-index for test data and train data\n",
    "                    conc_train.append(coxnet.score(X_train, y_train))\n",
    "                    conc_test.append(coxnet.score(X_test, y_test))\n",
    "\n",
    "                # Evaluate and record the results after each alpha and l1_ratio combination\n",
    "                avg_conc_test = np.mean(conc_test)\n",
    "                std_conc_test= np.std(conc_test)\n",
    "                avg_conc_train = np.mean(conc_train)\n",
    "\n",
    "                unimp_results_coxnet[(alpha, l1_ratio)] = [avg_conc_test, std_conc_test, avg_conc_train]\n",
    "\n",
    "                unimp_conc_coxnet[(alpha, l1_ratio)] = conc_test\n",
    "\n",
    "    preds_coxnet_mean_by_dataset[NaN_threshold] = unimp_results_coxnet\n",
    "    conc_coxnet_by_dataset[NaN_threshold] = unimp_conc_coxnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the result by the best Concordance (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for NaN_threshold, results in preds_coxnet_mean_by_dataset.items():\n",
    "    for (alpha, l1_ratio), metrics in results.items():\n",
    "        row = {\n",
    "            \"NaN_threshold\": NaN_threshold,\n",
    "            \"alpha\": alpha,\n",
    "            \"l1_ratio\": l1_ratio,\n",
    "            \"Conc test\": metrics[0],\n",
    "            \"Std Conc test\": metrics[1],\n",
    "            \"Conc train\": metrics[2],\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "unimp_scores_coxnet = pd.DataFrame(rows).sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "unimp_scores_coxnet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordance to each fold using the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimp_alpha = unimp_scores_coxnet['alpha'].iloc[0]\n",
    "unimp_l1_ratio = unimp_scores_coxnet['l1_ratio'].iloc[0]\n",
    "unimp_NaN_threshold = unimp_scores_coxnet['NaN_threshold'].iloc[0]\n",
    "\n",
    "unimp_best_conc_coxnet = conc_coxnet_by_dataset.get(unimp_NaN_threshold, {}).get((unimp_alpha, unimp_l1_ratio), \"Value not found\")\n",
    "unimp_best_conc_coxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COXNET (KNN Imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, tuple_y, target_columns = x_y_baseline(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for CoxPH model in sksurv\n",
    "alphas = [0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 3, 5, 10, 20, 50, 70, 100, 200, 500, 700, 1000]\n",
    "l1_ratios = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "imp_results_coxnet = {}\n",
    "imp_feature_importance_coxnet = {}\n",
    "imp_coefficients_coxnet = {}\n",
    "imp_conc_coxnet = {}\n",
    "\n",
    "for l1_ratio in l1_ratios:\n",
    "    for alpha in alphas:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            \n",
    "            coxnet = CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alphas=[alpha], fit_baseline_model=True)\n",
    "            conc_train = []\n",
    "            conc_test = []\n",
    "            brier = []\n",
    "            permut = []\n",
    "            coef = []\n",
    "            feature_importance = []\n",
    "            \n",
    "            print(f'alpha: {alpha}, l1_ratio: {l1_ratio}')\n",
    "        \n",
    "            for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                y_train, y_test = y[train], y[test]\n",
    "                \n",
    "                X_train, X_test = Preprocessing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                # fix the times            \n",
    "                times_train_min = y_train['time'].min()\n",
    "                times_train_max = y_train['time'].max()\n",
    "                times_train = np.arange(0, times_train_max)\n",
    "                times_test_min = y_test['time'].min()\n",
    "                times_test_max = y_test['time'].max()\n",
    "                if times_test_max > times_train_max:\n",
    "                    y_test_red_index = y_test['time'] <= times_train_max\n",
    "                    y_test = y_test[y_test_red_index]\n",
    "                    X_test = X_test[y_test_red_index]\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                \n",
    "                coxnet.fit(X_train, y_train)\n",
    "                \n",
    "                # Compute the C-index for test data and train data\n",
    "                conc_train.append(coxnet.score(X_train, y_train))\n",
    "                conc_test.append(coxnet.score(X_test, y_test))\n",
    "\n",
    "                # Brier Score\n",
    "                surv_prob_test = np.row_stack([fn(times_test) for fn in coxnet.predict_survival_function(X_test)])\n",
    "                brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "                importance = permutation_importance(coxnet,\n",
    "                                                    X_test,\n",
    "                                                    y_test,\n",
    "                                                    n_repeats=10,\n",
    "                                                    random_state=1)\n",
    "                permut.append(importance.importances_mean)\n",
    "\n",
    "                feature_importance.append(importance)\n",
    "                coef.append(coxnet.coef_)\n",
    "        \n",
    "            imp_feature_importance_coxnet[(alpha, l1_ratio)] = feature_importance\n",
    "            imp_coefficients_coxnet[(alpha, l1_ratio)] = coef\n",
    "\n",
    "            # Evaluate and record the results after each alpha and l1_ratio combination\n",
    "            avg_conc_test = np.mean(conc_test)\n",
    "            avg_conc_train = np.mean(conc_train)\n",
    "            avg_brier = np.mean(brier)\n",
    "            avg_permut = np.mean(permut)\n",
    "\n",
    "            imp_results_coxnet[(alpha, l1_ratio)] = [avg_conc_test, avg_conc_train, avg_brier, avg_permut]\n",
    "\n",
    "            imp_conc_coxnet[(alpha, l1_ratio)] = conc_test\n",
    "\n",
    "result = [{\n",
    "    'Alpha': alpha,\n",
    "    'L1 Ratio': l1_ratio,\n",
    "    'Conc test': avg_conc_test,\n",
    "    'Conc train': avg_conc_train,\n",
    "    'Brier Score': avg_brier,\n",
    "    'Permut': avg_permut\n",
    "} for (alpha, l1_ratio), (avg_conc_test, avg_conc_train, avg_brier, avg_permut) in imp_results_coxnet.items()]\n",
    "\n",
    "# Create the DataFrame\n",
    "imp_results_coxnet = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the result by the best Concordance (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_scores_coxnet = imp_results_coxnet.sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print out the sorted DataFrame\n",
    "imp_scores_coxnet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordance to each fold using the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_alpha = imp_scores_coxnet['Alpha'].iloc[0]\n",
    "imp_l1_ratio = imp_scores_coxnet['L1 Ratio'].iloc[0]\n",
    "imp_best_conc_coxnet= imp_conc_coxnet[(imp_alpha, imp_l1_ratio)]\n",
    "imp_best_conc_coxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "# Plot Q-Q plot for baseline_best_conc_coxnet in the first subplot\n",
    "stats.probplot(imp_best_conc_coxnet, dist=\"norm\", plot=axs[0, 0])\n",
    "axs[0, 0].set_title('Q-Q plot of KNN-Imputation')\n",
    "axs[0, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[0, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for baseline_best_conc_coxnet in the second subplot\n",
    "axs[0, 1].hist(imp_best_conc_coxnet, bins=10, color='salmon', edgecolor='black')\n",
    "axs[0, 1].set_title('Histogram of KNN-Imputation')\n",
    "axs[0, 1].set_xlabel('Value')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Plot Q-Q plot for MI_mean_conc in the third subplot\n",
    "stats.probplot(unimp_best_conc_coxnet, dist=\"norm\", plot=axs[1, 0])\n",
    "axs[1, 0].set_title('Q-Q plot of Baseline (Unimputed)')\n",
    "axs[1, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[1, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for MI_mean_conc in the fourth subplot\n",
    "axs[1, 1].hist(unimp_best_conc_coxnet, bins=10, color='salmon', edgecolor='black')\n",
    "axs[1, 1].set_title('Histogram of Baseline (Unimputed)')\n",
    "axs[1, 1].set_xlabel('Value')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.suptitle('Q-Q plot and Histogram of C-index to KNN-Imputation and baseline (Unimputed) - Coxnet', fontsize=20)\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Means Baseline (Unimputed): {round(np.mean(unimp_best_conc_coxnet), 3)} +/-{round(np.std(unimp_best_conc_coxnet), 3)} \\nMeans KNN Imputation: {round(np.mean(imp_best_conc_coxnet), 3)} +/-{round(np.std(imp_best_conc_coxnet), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(round(unimp_best_conc_coxnet, 3), round(imp_best_conc_coxnet, 4), alternative=\"two-sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COX PH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoxPH (unimputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for CoxPH model in sksurv\n",
    "alphas = [0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 3, 5, 10, 20, 50, 70, 100, 200, 500, 700, 1000]\n",
    "\n",
    "preds_coxph_mean_by_dataset = {}\n",
    "conc_coxph_by_dataset = {}\n",
    "\n",
    "NaN_thresholds = [3, 4, 5]\n",
    "\n",
    "for NaN_threshold in NaN_thresholds:\n",
    "    print(NaN_threshold)\n",
    "    file_path = '../../../Both/new_study.xlsx'\n",
    "    df = pd.read_excel(file_path, index_col='PATNO')\n",
    "    df = df.rename(columns={'OS (days)': 'time'})\n",
    "    df = df.rename(columns={'Status': 'status'})\n",
    "    df['status'] = df['status'].map({'Dead': True, 'Alive': False})\n",
    "    \n",
    "    df = preprocess_data(df, NaN_threshold)\n",
    "\n",
    "    X, y, tuple_y, target_columns = x_y_baseline(df)\n",
    "\n",
    "    unimp_results_coxph = {}\n",
    "    unimp_conc_coxph = {}\n",
    "\n",
    "\n",
    "    for alpha in alphas:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            \n",
    "            coxnet = CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alphas=[alpha], fit_baseline_model=True)\n",
    "            conc_train = []\n",
    "            conc_test = []\n",
    "            brier = []\n",
    "            permut = []\n",
    "            coef = []\n",
    "            feature_importance = []\n",
    "            \n",
    "            print(f'alpha: {alpha}')\n",
    "        \n",
    "            for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                y_train, y_test = y[train], y[test]\n",
    "                \n",
    "                X_train, X_test = Preprocessing_without_imputing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                # fix the times            \n",
    "                times_train_min = y_train['time'].min()\n",
    "                times_train_max = y_train['time'].max()\n",
    "                times_train = np.arange(0, times_train_max)\n",
    "                times_test_min = y_test['time'].min()\n",
    "                times_test_max = y_test['time'].max()\n",
    "                if times_test_max > times_train_max:\n",
    "                    y_test_red_index = y_test['time'] <= times_train_max\n",
    "                    y_test = y_test[y_test_red_index]\n",
    "                    X_test = X_test[y_test_red_index]\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                \n",
    "                coxnet.fit(X_train, y_train)\n",
    "                \n",
    "                # Compute the C-index for test data and train data\n",
    "                conc_train.append(coxnet.score(X_train, y_train))\n",
    "                conc_test.append(coxnet.score(X_test, y_test))\n",
    "\n",
    "            # Evaluate and record the results after each alpha and l1_ratio combination\n",
    "            avg_conc_test = np.mean(conc_test)\n",
    "            avg_conc_train = np.mean(conc_train)\n",
    "\n",
    "            unimp_results_coxph[(alpha)] = [avg_conc_test, avg_conc_train]\n",
    "\n",
    "            unimp_conc_coxph[(alpha)] = conc_test\n",
    "\n",
    "    preds_coxph_mean_by_dataset[NaN_threshold] = unimp_results_coxph\n",
    "    conc_coxph_by_dataset[NaN_threshold] = unimp_conc_coxph\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the result by the best Concordance (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for NaN_threshold, results in preds_coxph_mean_by_dataset.items():\n",
    "    for (alpha), metrics in results.items():\n",
    "        row = {\n",
    "            \"NaN_threshold\": NaN_threshold,\n",
    "            \"alpha\": alpha,\n",
    "            \"Conc test\": metrics[0],\n",
    "            \"Conc train\": metrics[1],\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "unimp_scores_coxph = pd.DataFrame(rows).sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "unimp_scores_coxph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimp_alpha = unimp_scores_coxph['alpha'].iloc[0]\n",
    "unimp_NaN_threshold = unimp_scores_coxph['NaN_threshold'].iloc[0]\n",
    "\n",
    "unimp_best_conc_coxph = conc_coxph_by_dataset.get(unimp_NaN_threshold, {}).get((unimp_alpha), \"Value not found\")\n",
    "unimp_best_conc_coxph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoxPH (Imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, tuple_y, target_columns = x_y_baseline(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for CoxPH model in sksurv\n",
    "alphas = [0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 3, 5, 10, 20, 50, 70, 100, 200, 500, 700, 1000]\n",
    "\n",
    "\n",
    "imp_results_coxph = {}\n",
    "imp_feature_importance_ph = {}\n",
    "imp_coefficients_coxph = {}\n",
    "imp_conc_coxph = {}\n",
    "\n",
    "for ind, alpha in enumerate(alphas):\n",
    "    # Note: For CoxnetSurvivalAnalysis, alphas should be a list (or array-like) even for a single value\n",
    "        conc_train = []\n",
    "        conc_test = []\n",
    "        brier = []\n",
    "        permut = []\n",
    "        feat_impor = []\n",
    "        coef = []\n",
    "\n",
    "        coxph = CoxPHSurvivalAnalysis(alpha=alpha, ties=\"efron\")\n",
    "\n",
    "        print(f'alpha: {alpha}')\n",
    "        \n",
    "        for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "            X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "            y_train, y_test = y[train], y[test]\n",
    "            \n",
    "            X_train, X_test = Preprocessing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                \n",
    "            # Train Model            \n",
    "            times_train_min = y_train['time'].min()\n",
    "            times_train_max = y_train['time'].max()\n",
    "            times_train = np.arange(0, times_train_max)\n",
    "            times_test_min = y_test['time'].min()\n",
    "            times_test_max = y_test['time'].max()\n",
    "            if times_test_max > times_train_max:\n",
    "                y_test_red_index = y_test['time'] <= times_train_max\n",
    "                y_test = y_test[y_test_red_index]\n",
    "                X_test = X_test[y_test_red_index]\n",
    "                times_test_max = y_test['time'].max()\n",
    "            times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "            \n",
    "            coxph.fit(X_train, y_train)\n",
    "            \n",
    "            # Compute the C-index for test data and train data\n",
    "            conc_train.append(coxph.score(X_train, y_train))\n",
    "            conc_test.append(coxph.score(X_test, y_test))\n",
    "\n",
    "            # Brier Score\n",
    "            surv_prob_test = np.row_stack([fn(times_test) for fn in coxph.predict_survival_function(X_test)])\n",
    "            brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "            importance = permutation_importance(coxph,\n",
    "                                                X_test,\n",
    "                                                y_test,\n",
    "                                                n_repeats=10,\n",
    "                                                random_state=1)\n",
    "            permut.append(importance.importances_mean)\n",
    "\n",
    "            feat_impor.append(importance)\n",
    "            coef.append(coxph.coef_)\n",
    "    \n",
    "        imp_feature_importance_ph[(alpha)] = feat_impor\n",
    "        imp_coefficients_coxph[(alpha)] = coef\n",
    "\n",
    "        # Evaluate and record the results after each alpha\n",
    "        avg_conc_test = np.mean(conc_test)\n",
    "        avg_conc_train = np.mean(conc_train)\n",
    "        avg_brier = np.mean(brier)\n",
    "        avg_permut = np.mean(permut)\n",
    "\n",
    "        imp_results_coxph[(alpha)] = [avg_conc_test, avg_conc_train, avg_brier, avg_permut]\n",
    "        imp_conc_coxph[(alpha)] = conc_test\n",
    "\n",
    "result = [{\n",
    "    'Alpha': alpha,\n",
    "    'Conc test': avg_conc_test,\n",
    "    'Conc train': avg_conc_train,\n",
    "    'Brier Score': avg_brier,\n",
    "    'Permut': avg_permut\n",
    "} for (alpha), (avg_conc_test, avg_conc_train, avg_brier, avg_permut) in imp_results_coxph.items()]\n",
    "\n",
    "# Create the DataFrame\n",
    "imp_results_coxph = pd.DataFrame(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the result by the best Concordance (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_scores_coxph = imp_results_coxph.sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print out the sorted DataFrame\n",
    "imp_scores_coxph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_alpha = imp_scores_coxph['Alpha'].iloc[0]\n",
    "imp_best_conc_coxph = imp_conc_coxph[(imp_alpha)]\n",
    "imp_best_conc_coxph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "# Plot Q-Q plot for baseline_best_conc_coxnet in the first subplot\n",
    "stats.probplot(imp_best_conc_coxph, dist=\"norm\", plot=axs[0, 0])\n",
    "axs[0, 0].set_title('Q-Q plot of KNN-Imputation')\n",
    "axs[0, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[0, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for baseline_best_conc_coxnet in the second subplot\n",
    "axs[0, 1].hist(imp_best_conc_coxph, bins=10, color='salmon', edgecolor='black')\n",
    "axs[0, 1].set_title('Histogram of KNN-Imputation')\n",
    "axs[0, 1].set_xlabel('Value')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Plot Q-Q plot for MI_mean_conc in the third subplot\n",
    "stats.probplot(unimp_best_conc_coxph, dist=\"norm\", plot=axs[1, 0])\n",
    "axs[1, 0].set_title('Q-Q plot of Baseline (Unimputed)')\n",
    "axs[1, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[1, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for MI_mean_conc in the fourth subplot\n",
    "axs[1, 1].hist(unimp_best_conc_coxph, bins=10, color='salmon', edgecolor='black')\n",
    "axs[1, 1].set_title('Histogram of Baseline (Unimputed)')\n",
    "axs[1, 1].set_xlabel('Value')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.suptitle('Q-Q plot and Histogram of C-index to KNN-Imputation and baseline (Unimputed) - CoxPH', fontsize=20)\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Means Baseline (Unimputed): {round(np.mean(unimp_best_conc_coxph), 3)} +/-{round(np.std(unimp_best_conc_coxph), 3)} \\nMeans KNN Imputation: {round(np.mean(imp_best_conc_coxph), 3)} +/-{round(np.std(imp_best_conc_coxph), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(unimp_best_conc_coxph, imp_best_conc_coxph, alternative=\"two-sided\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSurvivalForest (fewer parameter used than in the Modeling notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model (Unimputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 20, 30, 40, 50]  \n",
    "max_depths = [2, 3, 4, 5]\n",
    "min_samples_splits = [2, 6, 8] \n",
    "min_samples_leafs = [1, 2, 3, 4, 5, 6]  \n",
    "\n",
    "\n",
    "preds_rsf_mean_by_dataset = {}\n",
    "conc_rsf_by_dataset = {}\n",
    "\n",
    "NaN_thresholds = [3, 4, 5]\n",
    "\n",
    "for NaN_threshold in NaN_thresholds:\n",
    "    print(NaN_threshold)\n",
    "    file_path = '../../../Both/new_study.xlsx'\n",
    "    df = pd.read_excel(file_path, index_col='PATNO')\n",
    "    df = df.rename(columns={'OS (days)': 'time'})\n",
    "    df = df.rename(columns={'Status': 'status'})\n",
    "    df['status'] = df['status'].map({'Dead': True, 'Alive': False})\n",
    "    \n",
    "    df = preprocess_data(df, NaN_threshold)\n",
    "\n",
    "    X, y, tuple_y, target_columns = x_y_baseline(df)\n",
    "\n",
    "    unimp_results_rf = {}\n",
    "    unimp_conc_rf = {}\n",
    "\n",
    "    for n_estimator in n_estimators:\n",
    "        for max_depth in max_depths:\n",
    "            for min_samples_split in min_samples_splits:  \n",
    "                for min_samples_leaf in min_samples_leafs: \n",
    "                    rf = RandomSurvivalForest(\n",
    "                        n_estimators=n_estimator, \n",
    "                        max_depth=max_depth,\n",
    "                        min_samples_split=min_samples_split,\n",
    "                        min_samples_leaf=min_samples_leaf,\n",
    "                        random_state=173637)\n",
    "                    conc_train = []\n",
    "                    conc_test = []\n",
    "                    brier = []\n",
    "                    permut = []\n",
    "                    feat_impor = []\n",
    "                    coef = []\n",
    "                    \n",
    "                    print(f'n_estimator: {n_estimator}, max_depth: {max_depth}')\n",
    "\n",
    "                    for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                        y_train, y_test = y[train], y[test]\n",
    "                        \n",
    "                        X_train, X_test = Preprocessing_without_imputing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                            \n",
    "                        # fix the times            \n",
    "                        times_train_min = y_train['time'].min()\n",
    "                        times_train_max = y_train['time'].max()\n",
    "                        times_train = np.arange(0, times_train_max)\n",
    "                        times_test_min = y_test['time'].min()\n",
    "                        times_test_max = y_test['time'].max()\n",
    "                        if times_test_max > times_train_max:\n",
    "                            y_test_red_index = y_test['time'] <= times_train_max\n",
    "                            y_test = y_test[y_test_red_index]\n",
    "                            X_test = X_test[y_test_red_index]\n",
    "                            times_test_max = y_test['time'].max()\n",
    "                        times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                        \n",
    "                        rf.fit(X_train, y_train)\n",
    "                        \n",
    "                        # Compute the C-index for test data and train data\n",
    "                        conc_train.append(rf.score(X_train, y_train))\n",
    "                        conc_test.append(rf.score(X_test, y_test))\n",
    "\n",
    "                    # Evaluate and record the results after each n_estimator and max_depth combination\n",
    "                    avg_conc_test = np.mean(conc_test)\n",
    "                    avg_conc_train = np.mean(conc_train)\n",
    "\n",
    "                    unimp_results_rf[(n_estimator, max_depth, min_samples_split, min_samples_leaf)] = [avg_conc_test, avg_conc_train, avg_brier, avg_permut]\n",
    "                    unimp_conc_rf[(n_estimator, max_depth, min_samples_split, min_samples_leaf)] = conc_test\n",
    "\n",
    "    preds_rsf_mean_by_dataset[NaN_threshold] = unimp_results_rf\n",
    "    conc_rsf_by_dataset[NaN_threshold] = unimp_conc_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the result by the best Concordance (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for NaN_threshold, results in preds_rsf_mean_by_dataset.items():\n",
    "    for (n_estimator, max_depth, min_samples_split, min_samples_leaf), metrics in results.items():\n",
    "        row = {\n",
    "            \"NaN_threshold\": NaN_threshold,\n",
    "            \"n_estimator\": n_estimator,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "            \"Conc test\": metrics[0],\n",
    "            \"Conc train\": metrics[1],\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "unimp_scores_rf = pd.DataFrame(rows).sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "unimp_scores_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimp_n_estimator = unimp_scores_rf['n_estimator'].iloc[0]\n",
    "unimp_max_depth = unimp_scores_rf['max_depth'].iloc[0]\n",
    "unimp_min_samples_split = unimp_scores_rf['min_samples_split'].iloc[0]\n",
    "unimp_min_samples_leaf = unimp_scores_rf['min_samples_leaf'].iloc[0]\n",
    "unimp_NaN_threshold = unimp_scores_rf['NaN_threshold'].iloc[0]\n",
    "unimp_best_conc_rf = conc_rsf_by_dataset.get(unimp_NaN_threshold, {}).get((unimp_n_estimator, unimp_max_depth, unimp_min_samples_split, unimp_min_samples_leaf), \"Value not found\")\n",
    "unimp_best_conc_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSF (Imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, tuple_y, target_columns = x_y_baseline(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_results_rf = {}\n",
    "imp_feature_importance_rf = {}\n",
    "imp_conc_rf = {}\n",
    "\n",
    "n_estimators = [10, 20, 30, 40, 50]  \n",
    "max_depths = [2, 3, 4, 5]\n",
    "min_samples_splits = [2, 6, 8] \n",
    "min_samples_leafs = [1, 2, 3, 4, 5, 6]  \n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    for max_depth in max_depths:\n",
    "        for min_samples_split in min_samples_splits:  \n",
    "            for min_samples_leaf in min_samples_leafs: \n",
    "                rf = RandomSurvivalForest(\n",
    "                    n_estimators=n_estimator, \n",
    "                    max_depth=max_depth,\n",
    "                    min_samples_split=min_samples_split,\n",
    "                    min_samples_leaf=min_samples_leaf,\n",
    "                    random_state=173637)\n",
    "                \n",
    "                conc_train = []\n",
    "                conc_test = []\n",
    "                brier = []\n",
    "                permut = []\n",
    "                feat_impor = []\n",
    "                coef = []\n",
    "                \n",
    "                print(f'n_estimator: {n_estimator}, max_depth: {max_depth}')\n",
    "            \n",
    "                for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                    y_train, y_test = y[train], y[test]\n",
    "                    \n",
    "                    X_train, X_test = Preprocessing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                        \n",
    "                    # fix the times            \n",
    "                    times_train_min = y_train['time'].min()\n",
    "                    times_train_max = y_train['time'].max()\n",
    "                    times_train = np.arange(0, times_train_max)\n",
    "                    times_test_min = y_test['time'].min()\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                    if times_test_max > times_train_max:\n",
    "                        y_test_red_index = y_test['time'] <= times_train_max\n",
    "                        y_test = y_test[y_test_red_index]\n",
    "                        X_test = X_test[y_test_red_index]\n",
    "                        times_test_max = y_test['time'].max()\n",
    "                    times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                    \n",
    "                    rf.fit(X_train, y_train)\n",
    "                    \n",
    "                    # Compute the C-index for test data and train data\n",
    "                    conc_train.append(rf.score(X_train, y_train))\n",
    "                    conc_test.append(rf.score(X_test, y_test))\n",
    "\n",
    "                    # Brier Score\n",
    "                    surv_prob_test = np.row_stack([fn(times_test) for fn in rf.predict_survival_function(X_test)])\n",
    "                    brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "                    importance = permutation_importance(rf,\n",
    "                                                        X_test,\n",
    "                                                        y_test,\n",
    "                                                        n_repeats=10,\n",
    "                                                        random_state=1)\n",
    "                    permut.append(importance.importances_mean)\n",
    "\n",
    "                    feat_impor.append(importance)\n",
    "    \n",
    "                imp_feature_importance_rf[(n_estimator, max_depth, min_samples_split, min_samples_leaf)] = feat_impor\n",
    "\n",
    "                # Evaluate and record the results after each n_estimator and max_depth combination\n",
    "                avg_conc_test = np.mean(conc_test)\n",
    "                avg_conc_train = np.mean(conc_train)\n",
    "                avg_brier = np.mean(brier)\n",
    "                avg_permut = np.mean(permut)\n",
    "\n",
    "                imp_results_rf[(n_estimator, max_depth, min_samples_split, min_samples_leaf)] = [avg_conc_test, avg_conc_train, avg_brier, avg_permut]\n",
    "                imp_conc_rf[(n_estimator, max_depth, min_samples_split, min_samples_leaf)] = conc_test\n",
    "\n",
    "\n",
    "\n",
    "result = [{\n",
    "    'n_estimator': n_estimator,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'Conc test': avg_conc_test,\n",
    "    'Conc train': avg_conc_train,\n",
    "    'Brier Score': avg_brier,\n",
    "    'Permut': avg_permut\n",
    "} for (n_estimator, max_depth, min_samples_split, min_samples_leaf), (avg_conc_test, avg_conc_train, avg_brier, avg_permut) in imp_results_rf.items()]\n",
    "\n",
    "# Create the DataFrame\n",
    "imp_results_rf = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the result by the best Concordance (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_scores_rf = imp_results_rf.sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print out the sorted DataFrame\n",
    "imp_scores_rf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_n_estimator = imp_scores_rf['n_estimator'].iloc[0]\n",
    "imp_max_depth = imp_scores_rf['max_depth'].iloc[0]\n",
    "imp_min_samples_split = imp_scores_rf['min_samples_split'].iloc[0]\n",
    "imp_min_samples_leaf = imp_scores_rf['min_samples_leaf'].iloc[0]\n",
    "imp_best_conc_rf= imp_conc_rf[(imp_n_estimator, imp_max_depth, imp_min_samples_split, imp_min_samples_leaf)]\n",
    "imp_best_conc_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "# Plot Q-Q plot for baseline_best_conc_coxnet in the first subplot\n",
    "stats.probplot(imp_best_conc_rf, dist=\"norm\", plot=axs[0, 0])\n",
    "axs[0, 0].set_title('Q-Q plot of KNN-Imputation')\n",
    "axs[0, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[0, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for baseline_best_conc_coxnet in the second subplot\n",
    "axs[0, 1].hist(imp_best_conc_rf, bins=10, color='salmon', edgecolor='black')\n",
    "axs[0, 1].set_title('Histogram of KNN-Imputation')\n",
    "axs[0, 1].set_xlabel('Value')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Plot Q-Q plot for MI_mean_conc in the third subplot\n",
    "stats.probplot(unimp_best_conc_rf, dist=\"norm\", plot=axs[1, 0])\n",
    "axs[1, 0].set_title('Q-Q plot of Baseline (Unimputed)')\n",
    "axs[1, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[1, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for MI_mean_conc in the fourth subplot\n",
    "axs[1, 1].hist(unimp_best_conc_rf, bins=10, color='salmon', edgecolor='black')\n",
    "axs[1, 1].set_title('Histogram of Baseline (Unimputed)')\n",
    "axs[1, 1].set_xlabel('Value')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.suptitle('Q-Q plot and Histogram of C-index to KNN-Imputation and baseline (Unimputed) - RSF', fontsize=20)\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Means Baseline (Unimputed): {round(np.mean(unimp_best_conc_rf), 3)} +/-{round(np.std(unimp_best_conc_rf), 3)}\\nMeans KNN Imputation: {round(np.mean(imp_best_conc_rf), 3)} +/-{round(np.std(imp_best_conc_rf), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(unimp_best_conc_rf, imp_best_conc_rf, alternative=\"two-sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Componentwise Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model (Unimputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "\n",
    "# Cross validation for CoxPH model in sksurv\n",
    "n_estimators = [10, 20, 30, 40, 50]\n",
    "learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "subsamples = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "preds_cgb_mean_by_dataset = {}\n",
    "conc_cgb_by_dataset = {}\n",
    "\n",
    "NaN_thresholds = [3, 4, 5]\n",
    "\n",
    "for NaN_threshold in NaN_thresholds:\n",
    "    print(NaN_threshold)\n",
    "    file_path = '../../../Both/new_study.xlsx'\n",
    "    df = pd.read_excel(file_path, index_col='PATNO')\n",
    "    df = df.rename(columns={'OS (days)': 'time'})\n",
    "    df = df.rename(columns={'Status': 'status'})\n",
    "    df['status'] = df['status'].map({'Dead': True, 'Alive': False})\n",
    "    \n",
    "    df = preprocess_data(df, NaN_threshold)\n",
    "\n",
    "    X, y, tuple_y, target_columns = x_y_baseline(df)\n",
    "\n",
    "    unimp_results_cgb = {}\n",
    "    unimp_conc_cgb = {}\n",
    "\n",
    "    for n_estimator in n_estimators:\n",
    "        for learning_rate in learning_rates:\n",
    "            for subsample in subsamples:\n",
    "                cgb = ComponentwiseGradientBoostingSurvivalAnalysis(n_estimators=n_estimator,\n",
    "                                                                    learning_rate=learning_rate,\n",
    "                                                                    subsample = subsample,\n",
    "                                                                    random_state=173637)\n",
    "                conc_train = []\n",
    "                conc_test = []\n",
    "                brier = []\n",
    "                permut = []\n",
    "                feat_impor = []\n",
    "                coef = []\n",
    "                \n",
    "                print(f'n_estimator: {n_estimator}')\n",
    "\n",
    "                for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                    y_train, y_test = y[train], y[test]\n",
    "                    \n",
    "                    X_train, X_test = Preprocessing_without_imputing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                        \n",
    "                    # fix the times            \n",
    "                    times_train_min = y_train['time'].min()\n",
    "                    times_train_max = y_train['time'].max()\n",
    "                    times_train = np.arange(0, times_train_max)\n",
    "                    times_test_min = y_test['time'].min()\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                    if times_test_max > times_train_max:\n",
    "                        y_test_red_index = y_test['time'] <= times_train_max\n",
    "                        y_test = y_test[y_test_red_index]\n",
    "                        X_test = X_test[y_test_red_index]\n",
    "                        times_test_max = y_test['time'].max()\n",
    "                    times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                    \n",
    "                    cgb.fit(X_train, y_train)\n",
    "                    \n",
    "                    # Compute the C-index for test data and train data\n",
    "                    conc_train.append(cgb.score(X_train, y_train))\n",
    "                    conc_test.append(cgb.score(X_test, y_test))\n",
    "\n",
    "                    # Brier Score\n",
    "                    surv_prob_test = np.row_stack([fn(times_test) for fn in cgb.predict_survival_function(X_test)])\n",
    "                    brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "                # Evaluate and record the results after each n_estimator and max_depth combination\n",
    "                avg_conc_test = np.mean(conc_test)\n",
    "                avg_conc_train = np.mean(conc_train)\n",
    "                avg_brier = np.mean(brier)\n",
    "\n",
    "                unimp_results_cgb[(n_estimator, learning_rate, subsample)] = [avg_conc_test, avg_conc_train, avg_brier, avg_permut]\n",
    "                unimp_conc_cgb[(n_estimator, learning_rate, subsample)] = conc_test\n",
    "\n",
    "    preds_cgb_mean_by_dataset[NaN_threshold] = unimp_results_cgb\n",
    "    conc_cgb_by_dataset[NaN_threshold] = unimp_conc_cgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the result by the best Concordance (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for NaN_threshold, results in preds_cgb_mean_by_dataset.items():\n",
    "    for (n_estimator, learning_rate, subsample), metrics in results.items():\n",
    "        row = {\n",
    "            \"NaN_threshold\": NaN_threshold,\n",
    "            \"n_estimator\": n_estimator,\n",
    "            'learning_rate': learning_rate,\n",
    "            'subsample': subsample,\n",
    "            \"Conc test\": metrics[0],\n",
    "            \"Conc train\": metrics[1],\n",
    "            'Brier': metrics[2]\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "unimp_scores_cgb = pd.DataFrame(rows).sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "unimp_scores_cgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimp_n_estimator = unimp_scores_cgb['n_estimator'].iloc[0]\n",
    "unimp_learning_rate = unimp_scores_cgb['learning_rate'].iloc[0]\n",
    "unimp_subsample = unimp_scores_cgb['subsample'].iloc[0]\n",
    "unimp_NaN_threshold = unimp_scores_cgb['NaN_threshold'].iloc[0]\n",
    "unimp_best_conc_cgb = conc_cgb_by_dataset.get(unimp_NaN_threshold, {}).get((unimp_n_estimator, unimp_learning_rate, unimp_subsample), \"Value not found\")\n",
    "unimp_best_conc_cgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGB (Imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, tuple_y, target_columns = x_y_baseline(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "# loss: coxph\n",
    "n_estimators = [10, 20, 30, 40, 50]\n",
    "learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "subsamples = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "imp_results_cgb = {}\n",
    "imp_feature_importance_cgb = {}\n",
    "imp_conc_cgb = {}\n",
    "\n",
    "for learning_rate in learning_rates: \n",
    "        for n_estimator in n_estimators:\n",
    "            for subsample in subsamples:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                    cgb = ComponentwiseGradientBoostingSurvivalAnalysis(n_estimators=n_estimator,\n",
    "                                                                        learning_rate=learning_rate,\n",
    "                                                                        subsample = subsample,\n",
    "                                                                        random_state=173637)\n",
    "                    conc_train = []\n",
    "                    conc_test = []\n",
    "                    brier = []\n",
    "                    permut = []\n",
    "                    feat_impor = []\n",
    "                    coef = []\n",
    "                    \n",
    "                    print(f'learning_rate: {learning_rate}, n_estimator: {n_estimator}')\n",
    "                \n",
    "                    for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                        X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                        y_train, y_test = y[train], y[test]\n",
    "                        \n",
    "                        X_train, X_test = Preprocessing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                            \n",
    "                        # fix the times            \n",
    "                        times_train_min = y_train['time'].min()\n",
    "                        times_train_max = y_train['time'].max()\n",
    "                        times_train = np.arange(0, times_train_max)\n",
    "                        times_test_min = y_test['time'].min()\n",
    "                        times_test_max = y_test['time'].max()\n",
    "                        if times_test_max > times_train_max:\n",
    "                            y_test_red_index = y_test['time'] <= times_train_max\n",
    "                            y_test = y_test[y_test_red_index]\n",
    "                            X_test = X_test[y_test_red_index]\n",
    "                            times_test_max = y_test['time'].max()\n",
    "                        times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                        \n",
    "                        cgb.fit(X_train, y_train)\n",
    "                        \n",
    "                        # Compute the C-index for test data and train data\n",
    "                        conc_train.append(cgb.score(X_train, y_train))\n",
    "                        conc_test.append(cgb.score(X_test, y_test))\n",
    "\n",
    "                        # Brier Score\n",
    "                        surv_prob_test = np.row_stack([fn(times_test) for fn in cgb.predict_survival_function(X_test)])\n",
    "                        brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "                        importance = permutation_importance(cgb,\n",
    "                                                            X_test,\n",
    "                                                            y_test,\n",
    "                                                            n_repeats=10,\n",
    "                                                            random_state=1)\n",
    "                        permut.append(importance.importances_mean)\n",
    "\n",
    "                        feat_impor.append(importance)\n",
    "                \n",
    "                    imp_feature_importance_cgb[(n_estimator, learning_rate, subsample)] = feat_impor\n",
    "\n",
    "                    # Evaluate and record the results after each n_estimator and max_depth combination\n",
    "                    avg_conc_test = np.mean(conc_test)\n",
    "                    avg_conc_train = np.mean(conc_train)\n",
    "                    avg_brier = np.mean(brier)\n",
    "                    avg_permut = np.mean(permut)\n",
    "\n",
    "                    imp_results_cgb[(n_estimator, learning_rate, subsample)] = [avg_conc_test, avg_conc_train, avg_brier, avg_permut]\n",
    "                    imp_conc_cgb[(n_estimator, learning_rate, subsample)] = conc_test\n",
    "\n",
    "\n",
    "\n",
    "result = [{\n",
    "    'n_estimator': n_estimator,\n",
    "    'learning_rate': learning_rate, \n",
    "    'subsample': subsample,\n",
    "    'Conc test': avg_conc_test,\n",
    "    'Conc train': avg_conc_train,   \n",
    "    'Brier Score': avg_brier,\n",
    "    'Permut': avg_permut\n",
    "} for (n_estimator, learning_rate, subsample), (avg_conc_test, avg_conc_train, avg_brier, avg_permut) in imp_results_cgb.items()]\n",
    "\n",
    "# Create the DataFrame\n",
    "imp_results_cgb = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_scores_cgb = imp_results_cgb.sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print out the sorted DataFrame\n",
    "imp_scores_cgb.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-index to each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_n_estimator = imp_scores_cgb['n_estimator'].iloc[0]\n",
    "imp_learning_rate = imp_scores_cgb['learning_rate'].iloc[0]\n",
    "imp_subsample = imp_scores_cgb['subsample'].iloc[0]\n",
    "imp_best_conc_cgb= imp_conc_cgb[(imp_n_estimator, imp_learning_rate, imp_subsample)]\n",
    "imp_best_conc_cgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "# Plot Q-Q plot for baseline_best_conc_coxnet in the first subplot\n",
    "stats.probplot(imp_best_conc_cgb, dist=\"norm\", plot=axs[0, 0])\n",
    "axs[0, 0].set_title('Q-Q plot of KNN-Imputation')\n",
    "axs[0, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[0, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for baseline_best_conc_coxnet in the second subplot\n",
    "axs[0, 1].hist(imp_best_conc_cgb, bins=10, color='salmon', edgecolor='black')\n",
    "axs[0, 1].set_title('Histogram of KNN-Imputation')\n",
    "axs[0, 1].set_xlabel('Value')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Plot Q-Q plot for MI_mean_conc in the third subplot\n",
    "stats.probplot(unimp_best_conc_cgb, dist=\"norm\", plot=axs[1, 0])\n",
    "axs[1, 0].set_title('Q-Q plot of Baseline (Unimputed)')\n",
    "axs[1, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[1, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for MI_mean_conc in the fourth subplot\n",
    "axs[1, 1].hist(unimp_best_conc_cgb, bins=10, color='salmon', edgecolor='black')\n",
    "axs[1, 1].set_title('Histogram of Baseline (Unimputed)')\n",
    "axs[1, 1].set_xlabel('Value')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.suptitle('Q-Q plot and Histogram of C-index to KNN-Imputation and baseline (Unimputed) - RSF', fontsize=20)\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Means Baseline (Unimputed): {round(np.mean(unimp_best_conc_cgb), 3)} +/-{round(np.std(unimp_best_conc_cgb), 3)} \\nMeans KNN Imputation: {round(np.mean(imp_best_conc_cgb), 3)} +/-{round(np.std(imp_best_conc_cgb), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(unimp_best_conc_cgb, imp_best_conc_cgb, alternative=\"two-sided\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
