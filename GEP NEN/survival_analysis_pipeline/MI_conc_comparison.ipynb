{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from encoding import *\n",
    "from rubins_rules import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the model that perform best in Modeling notebook - Coxnet, for multiple imputation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "mcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=173637)\n",
    "from sksurv.metrics import (concordance_index_censored, \n",
    "                            integrated_brier_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through all multiple dataset data have been imputed by using multiple imputation methods with a range of different alphas and l1_ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "file_pattern = '../../R/datasets/MI/new_studyM*.csv'\n",
    "file_paths = glob.glob(file_pattern)\n",
    "\n",
    "alphas = [0.01, 0.05, 0.1, 0.5, 1, 3, 5, 10, 20, 50, 70, 100, 200, 500, 700, 1000]\n",
    "l1_ratios = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "coef_by_dataset = {}\n",
    "preds_coxnet_mean_by_dataset = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path, sep=',', index_col=0)\n",
    "    # Use a regular expression to find the part of the filename that matches \"M\" followed by any number(s)\n",
    "    match = re.search(r'M\\d+', file_path)\n",
    "    if match:\n",
    "        dataset_name = match.group()  # This will be 'M1', 'M2', etc.\n",
    "    \n",
    "    df = df.drop('PATNO', axis=1) \n",
    "\n",
    "    X, y, tuple_y, target_columns = x_y_multiple(df)  #kan sette train_df her\n",
    "\n",
    "    results_coxnet = {}\n",
    "    print(f'dataset name: {dataset_name}')\n",
    "\n",
    "    for l1_ratio in l1_ratios:\n",
    "        for alpha in alphas:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                warnings.filterwarnings(\"ignore\", message=\"overflow encountered in exp\")\n",
    "                \n",
    "                coxnet = CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alphas=[alpha], fit_baseline_model=True)\n",
    "                conc_train = []\n",
    "                conc_test = []\n",
    "                brier = []\n",
    "                \n",
    "                print(f'alpha: {alpha}, l1_ratio: {l1_ratio}')\n",
    "\n",
    "                # Iterate the folds\n",
    "                for train, test in mcv.split(X, tuple_y):  # legge inn X_train istedenfor X her\n",
    "                    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                    y_train, y_test = y[train], y[test]\n",
    "\n",
    "                    X_train, X_test = Preprocessing_without_imputing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "    \n",
    "                    # fix the times            \n",
    "                    times_train_min = y_train['time'].min()\n",
    "                    times_train_max = y_train['time'].max()\n",
    "                    times_train = np.arange(0, times_train_max)\n",
    "                    times_test_min = y_test['time'].min()\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                    if times_test_max > times_train_max:\n",
    "                        y_test_red_index = y_test['time'] <= times_train_max\n",
    "                        y_test = y_test[y_test_red_index]\n",
    "                        X_test = X_test[y_test_red_index]\n",
    "                        times_test_max = y_test['time'].max()\n",
    "                    times_test = np.arange(times_test_min, times_test_max)\n",
    "                            \n",
    "                    coxnet.fit(X_train, y_train)\n",
    "                    \n",
    "                    conc_train.append(coxnet.score(X_train, y_train))\n",
    "                    conc_test.append(coxnet.score(X_test, y_test))\n",
    "                    \n",
    "                    # Brier Score\n",
    "                    surv_prob_test = np.row_stack([fn(times_test) for fn in coxnet.predict_survival_function(X_test)])\n",
    "                    brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "                # Evaluate and record the results after each alpha and l1_ratio combination\n",
    "                avg_conc_test = np.mean(conc_test)\n",
    "                std_conc_test = np.std(conc_test)\n",
    "                avg_conc_train = np.mean(conc_train)\n",
    "                avg_brier = np.mean(brier)\n",
    "\n",
    "                results_coxnet[(alpha, l1_ratio)] = [avg_conc_test, std_conc_test, avg_conc_train, avg_brier]\n",
    "\n",
    "    preds_coxnet_mean_by_dataset[dataset_name] = results_coxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best score and parameters to each dataset\n",
    "\n",
    "This code finds the best hyperparameters for each dataset that yield the highest c-index (test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_data = []\n",
    "\n",
    "# Iterate over each dataset\n",
    "for dataset_name, results_coxnet in preds_coxnet_mean_by_dataset.items():\n",
    "    best_alpha = best_l1_ratio = None\n",
    "    best_avg_conc_test = float('-inf')  # Initialize with the lowest possible value\n",
    "    best_avg_conc_train = best_avg_brier = None\n",
    "    \n",
    "    # Find the model with the highest avg_conc_test for the current dataset\n",
    "    for (alpha, l1_ratio), values in results_coxnet.items():\n",
    "        avg_conc_test, std_conc_test, avg_conc_train, avg_brier = values\n",
    "        if avg_conc_test > best_avg_conc_test:\n",
    "            best_avg_conc_test = avg_conc_test\n",
    "            best_alpha, best_l1_ratio = alpha, l1_ratio\n",
    "            best_std_conc_test, best_avg_conc_train, best_avg_brier = std_conc_test, avg_conc_train, avg_brier\n",
    "    \n",
    "    # Append the best model data for the current dataset to the list\n",
    "    best_models_data.append({\n",
    "        'Dataset Name': dataset_name,\n",
    "        'Alpha': best_alpha,\n",
    "        'L1 Ratio': best_l1_ratio,\n",
    "        'Best Avg Conc Test': best_avg_conc_test,\n",
    "        'Best Std Conc Test': best_std_conc_test, \n",
    "        'Best Avg Conc Train': best_avg_conc_train,\n",
    "        'Best Avg Brier': best_avg_brier,\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list of best models data\n",
    "df_best_models = pd.DataFrame(best_models_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find those hyperparameter combinations that contain mostly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each (Alpha, L1 Ratio) pair\n",
    "alpha_l1_counts = df_best_models.groupby(['Alpha', 'L1 Ratio']).size().reset_index(name='Counts')\n",
    "\n",
    "# Find the row(s) with the maximum count\n",
    "most_common = alpha_l1_counts[alpha_l1_counts['Counts'] == alpha_l1_counts['Counts'].max()]\n",
    "\n",
    "print(\"Most common combinations of Alpha and L1 Ratio:\")\n",
    "most_common\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_alpha= most_common['Alpha'].iloc[0]\n",
    "MI_l1_ratio= most_common['L1 Ratio'].iloc[0]\n",
    "print(MI_alpha)\n",
    "print(MI_l1_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all the datasets again, but this time only using the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "file_pattern = '../../R/datasets/MI/new_studyM*.csv'\n",
    "file_paths = glob.glob(file_pattern)\n",
    "\n",
    "preds_coxnet_mean_by_dataset = {}\n",
    "MI_conc_coxnet_by_dataset = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path, sep=',', index_col=0)\n",
    "    # Use a regular expression to find the part of the filename that matches \"M\" followed by any number(s)\n",
    "    match = re.search(r'M\\d+', file_path)\n",
    "    if match:\n",
    "        dataset_name = match.group()  # This will be 'M1', 'M2', etc.\n",
    "\n",
    "    X, y, tuple_y, target_columns = x_y_multiple(df)\n",
    "\n",
    "    results_coxnet = {}\n",
    "\n",
    "   \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        \n",
    "        coxnet = CoxnetSurvivalAnalysis(l1_ratio=MI_l1_ratio, alphas=[MI_alpha], fit_baseline_model=True)\n",
    "        conc_train = []\n",
    "        conc_test = []\n",
    "        brier = []\n",
    "        \n",
    "        print(f'alpha: {MI_alpha}, l1_ratio: {MI_l1_ratio}')\n",
    "\n",
    "        # Iterate the folds\n",
    "        for train, test in mcv.split(X, tuple_y):\n",
    "            X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "            y_train, y_test = y[train], y[test]\n",
    "\n",
    "            X_train, X_test = Preprocessing_without_imputing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "\n",
    "\n",
    "            # fix the times            \n",
    "            times_train_min = y_train['time'].min()\n",
    "            times_train_max = y_train['time'].max()\n",
    "            times_train = np.arange(0, times_train_max)\n",
    "            times_test_min = y_test['time'].min()\n",
    "            times_test_max = y_test['time'].max()\n",
    "            if times_test_max > times_train_max:\n",
    "                y_test_red_index = y_test['time'] <= times_train_max\n",
    "                y_test = y_test[y_test_red_index]\n",
    "                X_test = X_test[y_test_red_index]\n",
    "                times_test_max = y_test['time'].max()\n",
    "            times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                    \n",
    "            coxnet.fit(X_train, y_train)\n",
    "\n",
    "            risk_scores = coxnet.predict(X_test)\n",
    "                        \n",
    "            conc_train.append(coxnet.score(X_train, y_train))\n",
    "            conc_test.append(coxnet.score(X_test, y_test))\n",
    "            \n",
    "            # Brier Score\n",
    "            surv_prob_test = np.row_stack([fn(times_test) for fn in coxnet.predict_survival_function(X_test)])\n",
    "            brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "        # Evaluate and record the results after each alpha and l1_ratio combination\n",
    "        avg_conc_test = np.mean(conc_test)\n",
    "        std_conc_test = np.std(conc_test)\n",
    "        avg_conc_train = np.mean(conc_train)\n",
    "        avg_brier = np.mean(brier)\n",
    "\n",
    "        results_coxnet[(MI_alpha, MI_l1_ratio)] = [avg_conc_test, std_conc_test, avg_conc_train, avg_brier]\n",
    "\n",
    "    preds_coxnet_mean_by_dataset[dataset_name] = results_coxnet\n",
    "    MI_conc_coxnet_by_dataset[dataset_name] = conc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for each dataset using the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare data for the DataFrame\n",
    "data_for_df = []\n",
    "\n",
    "# Loop through each dataset in preds_coxnet_mean_by_dataset\n",
    "for dataset_name, results_coxnet in preds_coxnet_mean_by_dataset.items():\n",
    "    # Each results_coxnet contains only one (alpha, l1_ratio) mapping to metrics\n",
    "    for (alpha, l1_ratio), (avg_conc_test, std_conc_test, avg_conc_train, avg_brier) in results_coxnet.items():\n",
    "        # Append the dataset name, parameters, and metrics to the data list\n",
    "        data_for_df.append([dataset_name, alpha, l1_ratio, avg_conc_test, std_conc_test, avg_conc_train, avg_brier])\n",
    "\n",
    "# Create the DataFrame\n",
    "MI_score = pd.DataFrame(data_for_df, columns=['Dataset Name', 'Alpha', 'L1 Ratio', 'Avg Conc Test', 'Std Conc Test', 'Avg Conc Train', 'Avg Brier'])\n",
    "\n",
    "# Display the DataFrame\n",
    "MI_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean: {np.mean(MI_score['Avg Conc Test']):.3f} +- {np.mean(MI_score['Std Conc Test']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-index to each fold\n",
    "\n",
    "`MI_conc_coxnet_by_dataset`contains a dictionary where each dataset is a key, and the corresponding value is a list containing all c-index values for all folds\n",
    "\n",
    "Because we have many dataset, we must take the mean across all the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(MI_conc_coxnet_by_dataset, orient='index').transpose()\n",
    "\n",
    "# Calculate the mean of each row\n",
    "MI_mean_conc = df.mean(axis=1).to_list()\n",
    "MI_mean_conc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model (KNN-imputation)\n",
    "\n",
    "Do the same now for the baseline model. Find the concordance to each fold to the best hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the path with the actual path to your file\n",
    "file_path = '../../../Both/new_study.xlsx'\n",
    "baseline_df = pd.read_excel(file_path, index_col='PATNO')\n",
    "baseline_df = baseline_df.rename(columns={'OS (days)': 'time'})\n",
    "baseline_df = baseline_df.rename(columns={'Status': 'status'})\n",
    "baseline_df['status'] = baseline_df['status'].map({'Dead': True, 'Alive': False})\n",
    "\n",
    "baseline_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finds the best model for Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, tuple_y, target_columns = x_y_baseline(baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for CoxPH model in sksurv\n",
    "alphas = [0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 3, 5, 10, 20, 50, 70, 100, 200, 500, 700, 1000]\n",
    "l1_ratios = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "results_coxnet = {}\n",
    "coefficients_coxnet = {}\n",
    "conc_coxnet = {}\n",
    "\n",
    "for l1_ratio in l1_ratios:\n",
    "    for alpha in alphas:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            \n",
    "            coxnet = CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alphas=[alpha], fit_baseline_model=True)\n",
    "            conc_train = []\n",
    "            conc_test = []\n",
    "            brier = []\n",
    "            coef = []\n",
    "            \n",
    "            print(f'alpha: {alpha}, l1_ratio: {l1_ratio}')\n",
    "        \n",
    "            for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                y_train, y_test = y[train], y[test]\n",
    "                \n",
    "                X_train, X_test = Preprocessing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                # fix the times            \n",
    "                times_train_min = y_train['time'].min()\n",
    "                times_train_max = y_train['time'].max()\n",
    "                times_train = np.arange(0, times_train_max)\n",
    "                times_test_min = y_test['time'].min()\n",
    "                times_test_max = y_test['time'].max()\n",
    "                if times_test_max > times_train_max:\n",
    "                    y_test_red_index = y_test['time'] <= times_train_max\n",
    "                    y_test = y_test[y_test_red_index]\n",
    "                    X_test = X_test[y_test_red_index]\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                \n",
    "                coxnet.fit(X_train, y_train)\n",
    "                \n",
    "                # Compute the C-index for test data and train data\n",
    "                conc_train.append(coxnet.score(X_train, y_train))\n",
    "                conc_test.append(coxnet.score(X_test, y_test))\n",
    "\n",
    "                # Brier Score\n",
    "                surv_prob_test = np.row_stack([fn(times_test) for fn in coxnet.predict_survival_function(X_test)])\n",
    "                brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "        \n",
    "            coefficients_coxnet[(alpha, l1_ratio)] = coef\n",
    "\n",
    "            # Evaluate and record the results after each alpha and l1_ratio combination\n",
    "            avg_conc_test = np.mean(conc_test)\n",
    "            avg_conc_train = np.mean(conc_train)\n",
    "            avg_brier = np.mean(brier)\n",
    "\n",
    "            results_coxnet[(alpha, l1_ratio)] = [avg_conc_test, avg_conc_train, avg_brier]\n",
    "\n",
    "            conc_coxnet[(alpha, l1_ratio)] = conc_test\n",
    "\n",
    "result = [{\n",
    "    'Alpha': alpha,\n",
    "    'L1 Ratio': l1_ratio,\n",
    "    'Conc test': avg_conc_test,\n",
    "    'Conc train': avg_conc_train,\n",
    "    'Brier Score': avg_brier,\n",
    "} for (alpha, l1_ratio), (avg_conc_test, avg_conc_train, avg_brier) in results_coxnet.items()]\n",
    "\n",
    "# Create the DataFrame\n",
    "results_coxnet = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_coxnet = results_coxnet.sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print out the sorted DataFrame\n",
    "scores_coxnet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finds the c-index to each fold to the best hyperparamets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_alpha = scores_coxnet['Alpha'].iloc[0]\n",
    "baseline_l1_ratio = scores_coxnet['L1 Ratio'].iloc[0]\n",
    "baseline_best_conc_coxnet= conc_coxnet[(baseline_alpha, baseline_l1_ratio)]\n",
    "baseline_best_conc_coxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unimputed Coxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for CoxPH model in sksurv\n",
    "alphas = [0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 3, 5, 10, 20, 50, 70, 100, 200, 500, 700, 1000]\n",
    "l1_ratios = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "preds_coxnet_mean_by_dataset = {}\n",
    "conc_coxnet_by_dataset = {}\n",
    "\n",
    "NaN_thresholds = [3, 4, 5]\n",
    "\n",
    "for NaN_threshold in NaN_thresholds:\n",
    "    print(NaN_threshold)\n",
    "    file_path = '../../../Both/new_study.xlsx'\n",
    "    df = pd.read_excel(file_path, index_col='PATNO')\n",
    "    df = df.rename(columns={'OS (days)': 'time'})\n",
    "    df = df.rename(columns={'Status': 'status'})\n",
    "    df['status'] = df['status'].map({'Dead': True, 'Alive': False})\n",
    "    \n",
    "    df = preprocess_data(df, NaN_threshold)\n",
    "\n",
    "    X, y, tuple_y, target_columns = x_y_baseline(df)\n",
    "\n",
    "    unimp_results_coxnet = {}\n",
    "    unimp_conc_coxnet = {}\n",
    "\n",
    "    for l1_ratio in l1_ratios:\n",
    "        for alpha in alphas:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "                \n",
    "                coxnet = CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alphas=[alpha], fit_baseline_model=True)\n",
    "                conc_train = []\n",
    "                conc_test = []\n",
    "                brier = []\n",
    "                permut = []\n",
    "                coef = []\n",
    "                feature_importance = []\n",
    "                \n",
    "                print(f'alpha: {alpha}, l1_ratio: {l1_ratio}')\n",
    "            \n",
    "                for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                    X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                    y_train, y_test = y[train], y[test]\n",
    "                    \n",
    "                    X_train, X_test = Preprocessing_without_imputing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                    # fix the times            \n",
    "                    times_train_min = y_train['time'].min()\n",
    "                    times_train_max = y_train['time'].max()\n",
    "                    times_train = np.arange(0, times_train_max)\n",
    "                    times_test_min = y_test['time'].min()\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                    if times_test_max > times_train_max:\n",
    "                        y_test_red_index = y_test['time'] <= times_train_max\n",
    "                        y_test = y_test[y_test_red_index]\n",
    "                        X_test = X_test[y_test_red_index]\n",
    "                        times_test_max = y_test['time'].max()\n",
    "                    times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                    \n",
    "                    coxnet.fit(X_train, y_train)\n",
    "                    \n",
    "                    # Compute the C-index for test data and train data\n",
    "                    conc_train.append(coxnet.score(X_train, y_train))\n",
    "                    conc_test.append(coxnet.score(X_test, y_test))\n",
    "\n",
    "                # Evaluate and record the results after each alpha and l1_ratio combination\n",
    "                avg_conc_test = np.mean(conc_test)\n",
    "                avg_conc_train = np.mean(conc_train)\n",
    "\n",
    "                unimp_results_coxnet[(alpha, l1_ratio)] = [avg_conc_test, avg_conc_train]\n",
    "\n",
    "                unimp_conc_coxnet[(alpha, l1_ratio)] = conc_test\n",
    "\n",
    "    preds_coxnet_mean_by_dataset[NaN_threshold] = unimp_results_coxnet\n",
    "    conc_coxnet_by_dataset[NaN_threshold] = unimp_conc_coxnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for NaN_threshold, results in preds_coxnet_mean_by_dataset.items():\n",
    "    for (alpha, l1_ratio), metrics in results.items():\n",
    "        row = {\n",
    "            \"NaN_threshold\": NaN_threshold,\n",
    "            \"alpha\": alpha,\n",
    "            \"l1_ratio\": l1_ratio,\n",
    "            \"Conc test\": metrics[0],\n",
    "            \"Conc train\": metrics[1],\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "unimp_scores_coxnet = pd.DataFrame(rows).sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "unimp_scores_coxnet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C-index for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimp_alpha = unimp_scores_coxnet['alpha'].iloc[0]\n",
    "unimp_l1_ratio = unimp_scores_coxnet['l1_ratio'].iloc[0]\n",
    "unimp_NaN_threshold = unimp_scores_coxnet['NaN_threshold'].iloc[0]\n",
    "\n",
    "unimp_best_conc_coxnet = conc_coxnet_by_dataset.get(unimp_NaN_threshold, {}).get((unimp_alpha, unimp_l1_ratio), \"Value not found\")\n",
    "unimp_best_conc_coxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal distribution\n",
    "To use t-test, we must check that the data is normal distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "# Plot Q-Q plot for baseline_best_conc_coxnet in the first subplot\n",
    "stats.probplot(unimp_best_conc_coxnet, dist=\"norm\", plot=axs[0, 0])\n",
    "axs[0, 0].set_title('Q-Q plot of Baseline (Unimputed)')\n",
    "axs[0, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[0, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for baseline_best_conc_coxnet in the second subplot\n",
    "axs[0, 1].hist(unimp_best_conc_coxnet, bins=10, color='salmon', edgecolor='black')\n",
    "axs[0, 1].set_title('Histogram of Baseline (Unimputed)')\n",
    "axs[0, 1].set_xlabel('Value')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Plot Q-Q plot for MI_mean_conc in the third subplot\n",
    "stats.probplot(MI_mean_conc, dist=\"norm\", plot=axs[1, 0])\n",
    "axs[1, 0].set_title('Q-Q plot of MI')\n",
    "axs[1, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[1, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for MI_mean_conc in the fourth subplot\n",
    "axs[1, 1].hist(MI_mean_conc, bins=10, color='salmon', edgecolor='black')\n",
    "axs[1, 1].set_title('Histogram of MI')\n",
    "axs[1, 1].set_xlabel('Value')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout\n",
    "plt.suptitle('Q-Q plot and Histogram of concordances in MI and Baseline (Unimputed)', fontsize=20)\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 6))\n",
    "\n",
    "# Plot Q-Q plot for baseline_best_conc_coxnet in the first subplot\n",
    "stats.probplot(baseline_best_conc_coxnet, dist=\"norm\", plot=axs[0, 0])\n",
    "axs[0, 0].set_title('Q-Q plot of KNN-Imputation')\n",
    "axs[0, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[0, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for baseline_best_conc_coxnet in the second subplot\n",
    "axs[0, 1].hist(baseline_best_conc_coxnet, bins=10, color='salmon', edgecolor='black')\n",
    "axs[0, 1].set_title('Histogram of KNN-Imputation')\n",
    "axs[0, 1].set_xlabel('Value')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Plot Q-Q plot for MI_mean_conc in the third subplot\n",
    "stats.probplot(MI_mean_conc, dist=\"norm\", plot=axs[1, 0])\n",
    "axs[1, 0].set_title('Q-Q plot of MI')\n",
    "axs[1, 0].set_xlabel('Theoretical quantiles')\n",
    "axs[1, 0].set_ylabel('Ordered Values')\n",
    "\n",
    "# Plot histogram for MI_mean_conc in the fourth subplot\n",
    "axs[1, 1].hist(MI_mean_conc, bins=10, color='salmon', edgecolor='black')\n",
    "axs[1, 1].set_title('Histogram of MI')\n",
    "axs[1, 1].set_xlabel('Value')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout\n",
    "plt.suptitle('Q-Q plot and Histogram of concordances in MI and KNN-Imputation', fontsize=20)\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between KNN-imputation and Mulitple Imputation by using the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Means MI: {np.mean(MI_score['Avg Conc Test']):.3f} +/-{np.mean(MI_score['Std Conc Test']):.3f}\\nMeans KNN Imputation: {round(np.mean(baseline_best_conc_coxnet), 3)} +/-{round(np.std(baseline_best_conc_coxnet), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(MI_mean_conc, baseline_best_conc_coxnet, alternative=\"two-sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Unimputation and Mulitple Imputation by using the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Means MI: {round(np.mean(MI_mean_conc), 3)}\\nBaseline (Unimputed) : {round(np.mean(unimp_best_conc_coxnet), 3)}\")\n",
    "print(f\"Means MI: {np.mean(MI_score['Avg Conc Test']):.3f} +/-{np.mean(MI_score['Std Conc Test']):.3f}\\nBaseline (Unimputed) : {round(np.mean(unimp_best_conc_coxnet), 3)} +/-{round(np.std(unimp_best_conc_coxnet), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(MI_mean_conc, unimp_best_conc_coxnet, alternative=\"two-sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based imputation (single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = '/Users/ninarebeccalizana/Documents/Master/code/New-Study/R/datasets/singlenew_studyM1.csv'\n",
    "\n",
    "df = pd.read_csv(file_pattern, sep=',', index_col=0)\n",
    "df = df.drop('PATNO', axis=1) \n",
    "\n",
    "X, y, tuple_y, target_columns = x_y_multiple(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for CoxPH model in sksurv\n",
    "alphas = [0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 3, 5, 10, 20, 50, 70, 100, 200, 500, 700, 1000]\n",
    "l1_ratios = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "single_results_coxnet = {}\n",
    "single_coefficients_coxnet = {}\n",
    "single_conc_coxnet = {}\n",
    "\n",
    "for l1_ratio in l1_ratios:\n",
    "    for alpha in alphas:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "            \n",
    "            coxnet = CoxnetSurvivalAnalysis(l1_ratio=l1_ratio, alphas=[alpha], fit_baseline_model=True)\n",
    "            conc_train = []\n",
    "            conc_test = []\n",
    "            brier = []\n",
    "            coef = []\n",
    "            \n",
    "            print(f'alpha: {alpha}, l1_ratio: {l1_ratio}')\n",
    "        \n",
    "            for i, (train, test) in enumerate(mcv.split(X, tuple_y)):\n",
    "                X_train, X_test = X.iloc[train], X.iloc[test]\n",
    "                y_train, y_test = y[train], y[test]\n",
    "                \n",
    "                X_train, X_test = Preprocessing(X_train=X_train, X_test=X_test, y_train=y_train, target_columns=target_columns)\n",
    "                # fix the times            \n",
    "                times_train_min = y_train['time'].min()\n",
    "                times_train_max = y_train['time'].max()\n",
    "                times_train = np.arange(0, times_train_max)\n",
    "                times_test_min = y_test['time'].min()\n",
    "                times_test_max = y_test['time'].max()\n",
    "                if times_test_max > times_train_max:\n",
    "                    y_test_red_index = y_test['time'] <= times_train_max\n",
    "                    y_test = y_test[y_test_red_index]\n",
    "                    X_test = X_test[y_test_red_index]\n",
    "                    times_test_max = y_test['time'].max()\n",
    "                times_test = np.arange(times_test_min, times_test_max)\n",
    "\n",
    "                \n",
    "                coxnet.fit(X_train, y_train)\n",
    "                \n",
    "                # Compute the C-index for test data and train data\n",
    "                conc_train.append(coxnet.score(X_train, y_train))\n",
    "                conc_test.append(coxnet.score(X_test, y_test))\n",
    "\n",
    "                # Brier Score\n",
    "                surv_prob_test = np.row_stack([fn(times_test) for fn in coxnet.predict_survival_function(X_test)])\n",
    "                brier.append(integrated_brier_score(y_train, y_test, surv_prob_test, times_test))\n",
    "\n",
    "        \n",
    "            single_coefficients_coxnet[(alpha, l1_ratio)] = coef\n",
    "\n",
    "            # Evaluate and record the results after each alpha and l1_ratio combination\n",
    "            avg_conc_test = np.mean(conc_test)\n",
    "            avg_conc_train = np.mean(conc_train)\n",
    "            avg_brier = np.mean(brier)\n",
    "\n",
    "            single_results_coxnet[(alpha, l1_ratio)] = [avg_conc_test, avg_conc_train, avg_brier]\n",
    "\n",
    "            single_conc_coxnet[(alpha, l1_ratio)] = conc_test\n",
    "\n",
    "result = [{\n",
    "    'Alpha': alpha,\n",
    "    'L1 Ratio': l1_ratio,\n",
    "    'Conc test': avg_conc_test,\n",
    "    'Conc train': avg_conc_train,\n",
    "    'Brier Score': avg_brier,\n",
    "} for (alpha, l1_ratio), (avg_conc_test, avg_conc_train, avg_brier) in single_results_coxnet.items()]\n",
    "\n",
    "# Create the DataFrame\n",
    "single_results_coxnet = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_scores_coxnet = single_results_coxnet.sort_values(by='Conc test', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print out the sorted DataFrame\n",
    "single_scores_coxnet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the c-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_alpha = single_scores_coxnet['Alpha'].iloc[0]\n",
    "single_l1_ratio = single_scores_coxnet['L1 Ratio'].iloc[0]\n",
    "single_best_conc_coxnet= single_conc_coxnet[(baseline_alpha, baseline_l1_ratio)]\n",
    "single_best_conc_coxnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between KNN-imputation and single based-model by using the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model-based (single): {round(np.mean(single_best_conc_coxnet), 3)} +/-{round(np.std(single_best_conc_coxnet), 3)}\\nKNN imputation : {round(np.mean(baseline_best_conc_coxnet), 3)} +/-{round(np.std(baseline_best_conc_coxnet), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(single_best_conc_coxnet, baseline_best_conc_coxnet, alternative=\"two-sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Unimputed and single based-model by using the t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model-based (single): {round(np.mean(single_best_conc_coxnet),3)}\\nBaseline (unimputed) : {round(np.mean(unimp_best_conc_coxnet), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(single_best_conc_coxnet, unimp_best_conc_coxnet, alternative=\"two-sided\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
